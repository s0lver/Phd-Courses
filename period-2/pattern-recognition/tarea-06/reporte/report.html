<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta name="generator" content="hevea 2.09">
<style type="text/css">
.li-itemize{margin:1ex 0ex;}
.li-enumerate{margin:1ex 0ex;}
.dd-description{margin:0ex 0ex 1ex 4ex;}
.dt-description{margin:0ex;}
.toc{list-style:none;}
.footnotetext{margin:0ex; padding:0ex;}
div.footnotetext P{margin:0px; text-indent:1em;}
.thefootnotes{text-align:left;margin:0ex;}
.dt-thefootnotes{margin:0em;}
.dd-thefootnotes{margin:0em 0em 0em 2em;}
.footnoterule{margin:1em auto 1em 0px;width:50%;}
.caption{padding-left:2ex; padding-right:2ex; margin-left:auto; margin-right:auto}
.title{margin:2ex auto;text-align:center}
.titlemain{margin:1ex 2ex 2ex 1ex;}
.titlerest{margin:0ex 2ex;}
.center{text-align:center;margin-left:auto;margin-right:auto;}
.flushleft{text-align:left;margin-left:0ex;margin-right:auto;}
.flushright{text-align:right;margin-left:auto;margin-right:0ex;}
div table{margin-left:inherit;margin-right:inherit;margin-bottom:2px;margin-top:2px}
td table{margin:auto;}
table{border-collapse:collapse;}
td{padding:0;}
.cellpadding0 tr td{padding:0;}
.cellpadding1 tr td{padding:1px;}
pre{text-align:left;margin-left:0ex;margin-right:auto;}
blockquote{margin-left:4ex;margin-right:4ex;text-align:left;}
td p{margin:0px;}
.boxed{border:1px solid black}
.textboxed{border:1px solid black}
.vbar{border:none;width:2px;background-color:black;}
.hbar{border:none;height:2px;width:100%;background-color:black;}
.hfill{border:none;height:1px;width:200%;background-color:black;}
.vdisplay{border-collapse:separate;border-spacing:2px;width:auto; empty-cells:show; border:2px solid red;}
.vdcell{white-space:nowrap;padding:0px; border:2px solid green;}
.display{border-collapse:separate;border-spacing:2px;width:auto; border:none;}
.dcell{white-space:nowrap;padding:0px; border:none;}
.dcenter{margin:0ex auto;}
.vdcenter{border:solid #FF8000 2px; margin:0ex auto;}
.minipage{text-align:left; margin-left:0em; margin-right:auto;}
.marginpar{border:solid thin black; width:20%; text-align:left;}
.marginparleft{float:left; margin-left:0ex; margin-right:1ex;}
.marginparright{float:right; margin-left:1ex; margin-right:0ex;}
.theorem{text-align:left;margin:1ex auto 1ex 0ex;}
.part{margin:2ex auto;text-align:center}
.lstlisting{font-family:monospace;white-space:pre;margin-right:auto;margin-left:0pt;text-align:left}
</style>
<title>Red Neuronal de base radial (RBFN)
</title>
</head>
<body >
<!--HEVEA command line is: /usr/bin/hevea article.hva report.tex -->
<!--CUT STYLE article--><!--CUT DEF section 1 --><p>algorithmPseudocódigo
</p><table class="title"><tr><td style="padding:1ex"><h1 class="titlemain">Red Neuronal de base radial (<em>RBFN</em>)</h1><h3 class="titlerest">Rafael Pérez Torres <br>
	Profesor: Dr. Wilfrido Gómez Flores,<br>
LTI Cinvestav.
	
	</h3></td></tr>
</table><blockquote class="abstract"><span style="font-weight:bold">Abstract: </span>
Las redes neuronales de función de base radial (RBFN) son una alternativa al perceptrón multicapa.
A diferencia del perceptrón multicapa, las redes neuronales de función de base radial no requieren realizar la retropropagación del error para realizar el ajuste de los pesos y además mantienen una estructura fija compuesta de una capa de entrada, una capa escondifa y una de salida.<p>Este tipo de redes resultan útiles para aproximar funciones y además realizar la clasificación de patrones.</p><p>En este documento se presenta la implementación del entrenamiento híbrido y clasificación utilizando una red neuronal de función de base radial.
El entrenamiento se ha realizado variando la cantidad de neuronas en la capa oculta, así como la función de media utilizada para realizar el cálculo de los radios.
Se muestran las regiones particionadas generadas por las mejores configuraciones obtenidas durante el entrenamiento.
</p></blockquote><p>
Reconocimiento de patrones, Redes neuronales de función de base radial, RBFN
</p>
<!--TOC section id="sec1" Introducción-->
<h2 id="sec1" class="section">1  Introducción</h2><!--SEC END --><p>
<a id="sec:introduccion"></a></p><p>Las redes funcionales de función de base radial surgen como un método alternativo al perceptrón multicapa, siendo propuestas por Broomhead y Lowe en el año de 1988.</p><p>Este tipo de redes definen una topología fija consistente en las siguientes capas:
</p><ul class="itemize"><li class="li-itemize">
	<span style="font-weight:bold">Entrada</span>: recibe y distribuye los datos desde el exterior.
	</li><li class="li-itemize"><span style="font-weight:bold">Oculta</span>: activada por funciones radiales <em>no lineales</em>.
	</li><li class="li-itemize"><span style="font-weight:bold">Salida</span>: activada por funciones <em>lineales</em> continuas.
</li></ul><p>La salida de este tipo de redes está definida por una transformación no lineal en la capa oculta y una lineal en la capa de salida.
Existen múltiples funciones de tansformación no lineal.
Dentro de las más comunes se encuentran
</p><ul class="itemize"><li class="li-itemize">
	Función Gaussiana.
	</li><li class="li-itemize">Función multicuadrática.
	</li><li class="li-itemize">Función multicuadrática generalizada.
	</li><li class="li-itemize">Función multicuadrática inversa.
	</li><li class="li-itemize">Función multicuadrática inversa generalizada.
</li></ul><p>Las siguientes secciones describen de forma breve el marco teórico tras el entrenamiento y la clasificación de las RBFN.</p>
<!--TOC section id="sec2" Marco teórico-->
<h2 id="sec2" class="section">2  Marco teórico</h2><!--SEC END --><p>
<a id="sec:marco_teorico"></a>
El entrenamiento y la clasificación de una RBFN conllevan procesos similares, cuyo común denominador, es la función de activación (transferencia) evaluada en cada una de las neuronas.</p><p>La función Gaussiana es la más utilizada con estos fines, siendo definida como:
</p><table class="display dcenter"><tr style="vertical-align:middle"><td class="dcell">φ<sub><span style="font-style:italic">i</span></sub> (<span style="font-style:italic">x</span>) = exp(−</td><td class="dcell"><table class="display"><tr><td class="dcell" style="text-align:center">||<span style="font-style:italic">x</span>−<span style="font-style:italic">C</span><sub><span style="font-style:italic">i</span></sub>||</td></tr>
<tr><td class="hbar"></td></tr>
<tr><td class="dcell" style="text-align:center">2σ<sub><span style="font-style:italic">i</span></sub><sup>2</sup></td></tr>
</table></td><td class="dcell">)
</td></tr>
</table><p>
donde ||−|| es la distancia Euclideana entre el vector de entrada <span style="font-style:italic">x</span> y el centro de la <span style="font-style:italic">i</span>-ésima neurona oculta.</p><p>Las RBF definen zonas que pueden entenderse como regiones sensibles que se activarán de mayor forma cuando el patrón a clasificar esté más cerca de su centroide, es por ello que se les conoce como de <em>carácter local</em>.
Este comportamiento puede ser modelado como:
</p><table class="display dcenter"><tr style="vertical-align:middle"><td class="dcell">φ <sub><span style="font-style:italic">i</span></sub> (<span style="font-style:italic">x</span>) → 1  cuando ||<span style="font-style:italic">x</span>−<span style="font-style:italic">C</span><sub><span style="font-style:italic">i</span></sub>||→ 0
</td></tr>
</table><p>La salida de una RBFN es una combinación lineal de RBFs, en la que cada una se activa para una porción del espacio de características definidas por los patrones de entrada.</p><p>Así, la configuración de una RBFN es como se muestra en la Figura REFERENCIA-FIGURA, donde puede observarse la contribución de las entradas hacia la capa oculta, luego en cada neurona de la capa oculta se evalúa la entrada con la función de activación, para luego obtener una lista de pesos que ponderan los datos de entradas y que son acumulados en la capa de salida para obtener la respuesta de la red.</p><p>Las siguientes secciones describen los procesos de entrenamiento y clasificación.
</p>
<!--TOC subsection id="sec3" Entrenamiento de una RBFN-->
<h3 id="sec3" class="subsection">2.1  Entrenamiento de una RBFN</h3><!--SEC END --><p> <a id="sub:entrenamiento_de_una_RNA"></a>
El entrenamiento de una RBFN es realizado de forma híbrida, dividiéndose entre las capas oculta y de salida:
</p><ul class="itemize"><li class="li-itemize">
	<span style="font-weight:bold">Capa oculta</span>: Se realiza de forma no supervisada tratando de encontrar los centros y radios de las neuronas de la RBFN.
	</li><li class="li-itemize"><span style="font-weight:bold">Capa de salida</span>: Se realiza de forma supervisada, tratando de encontrar los pesos sinápticos.
</li></ul><p>Este entrenamiento híbrido puede realizarse combinando distintas técnicas; al final el objetivo es obtener una buena generalización y a la vez que se obtenga un nivel bajo de error.</p><p>Por ejemplo, para esta asignación se ha utilizado el algoritmo <em>k-means</em> para realizar la búsqueda de los centros de las neuronas.</p><p>Como es sabido, el algoritmo <em>k-means</em> permite, a partir de un valor de k grupos, agrupar a todos los datos dependiendo de su cercanía a uno de los <span style="font-style:italic">k</span> centroides.
De forma iterativa, este algoritmo buscará mejorar la distribución de los datos respecto a los centroides, de tal forma que se obtenga la menor distancia entre ellos, finalizando cuando ya no se encuentren movimientos en la agrupación.</p><p>Para el cálculo de los radios de estas neuronas se pueden seguir los enfoques de:
</p><ul class="itemize"><li class="li-itemize">
	<span style="font-weight:bold">Media uniforme</span>: En el que se miden las distancias euclideanas del centroide <span style="font-style:italic">C</span><sub><span style="font-style:italic">i</span></sub> hacia los <span style="font-style:italic">p</span> centroides más cercanos, calculándose el radio como <table class="display dcenter"><tr style="vertical-align:middle"><td class="dcell">σ <sub><span style="font-style:italic">i</span></sub> = </td><td class="dcell"><table style="border-spacing:0" class="cellpadding0"><tr><td ALIGN="right"><div CLASS="vbar" STYLE="height:2em;"></div></td></tr>
<tr><td><span style="font-size:xx-large"><span style="font-size:150%">√</span></span></td></tr>
</table></td><td class="dcell"><table style="border:0;border-spacing:1;border-collapse:separate;" class="cellpadding0"><tr><td class="hbar"></td></tr>
<tr><td style="text-align:center;white-space:nowrap" ><table class="display"><tr style="vertical-align:middle"><td class="dcell"><table class="display"><tr><td class="dcell" style="text-align:center">1</td></tr>
<tr><td class="hbar"></td></tr>
<tr><td class="dcell" style="text-align:center"><span style="font-style:italic">p</span></td></tr>
</table></td><td class="dcell"><table class="display"><tr><td class="dcell" style="text-align:center"><span style="font-style:italic">p</span></td></tr>
<tr><td class="dcell" style="text-align:center"><span style="font-size:xx-large">∑</span></td></tr>
<tr><td class="dcell" style="text-align:center"><span style="font-style:italic">i</span>=1</td></tr>
</table></td><td class="dcell"> (<span style="font-style:italic">C</span><sub><span style="font-style:italic">i</span></sub> − <span style="font-style:italic">C</span><sub><span style="font-style:italic">p</span></sub>)<sup>2</sup></td></tr>
</table></td></tr>
</table></td></tr>
</table>.
	</li><li class="li-itemize"><span style="font-weight:bold">Media geométrica</span>: en el que el radio se calcula a partir de la distancia de un centroide <span style="font-style:italic">C</span><sub><span style="font-style:italic">i</span></sub> a dos centroides vecinos más cercanos: <table class="display dcenter"><tr style="vertical-align:middle"><td class="dcell">σ <sub><span style="font-style:italic">i</span></sub> = </td><td class="dcell"><span style="font-size:x-large">√</span></td><td class="dcell"><table style="border:0;border-spacing:1;border-collapse:separate;" class="cellpadding0"><tr><td class="hbar"></td></tr>
<tr><td style="text-align:center;white-space:nowrap" >||<span style="font-style:italic">C</span><sub><span style="font-style:italic">i</span></sub> − <span style="font-style:italic">C</span><sub><span style="font-style:italic">a</span></sub>||*||<span style="font-style:italic">C</span><sub><span style="font-style:italic">i</span></sub> − <span style="font-style:italic">C</span><sub><span style="font-style:italic">b</span></sub>||</td></tr>
</table></td></tr>
</table>
</li></ul><p>Para el entrenamiento en la capa de salida, el cuál es supervisado , la intención es minimizar las diferencias entre la slaida de la red y las salidas deseadas.</p><p>Es posible utilizar el método de la matriz pseudoinversa para obtener una solución directa.
La solución es dada por:
</p><table class="display dcenter"><tr style="vertical-align:middle"><td class="dcell"><span style="font-style:italic">W</span> = <span style="font-style:italic">G</span><sup>+</sup><span style="font-style:italic">S</span> = (<span style="font-style:italic">G</span><sup><span style="font-style:italic">T</span></sup> <span style="font-style:italic">G</span>)<sup>−1</sup><span style="font-style:italic">G</span><sup><span style="font-style:italic">T</span></sup> <span style="font-style:italic">S</span>
</td></tr>
</table><p>
donde <span style="font-style:italic">G</span> contiene las activaciones de las neuronas de la capa oculta para los patrones de entrada <span style="font-style:italic">x</span>, <span style="font-style:italic">S</span> es la amtriz de salidas deseadas y <span style="font-style:italic">W</span> es la matriz de pesos.</p><p>Debido a la dificultad para encontrar el parámetro adecuado que indique la cantidad de neuronas en la capa oculta en una RBFN, es posible utilizar un enfoque para calcular este parámetro, así como para validar que cada una de las configuraciones no esté causando un sobreajuste o sobreentrenamiento en la red.
Para ello, se construye un mecanismo como el descrito en el Pseudocódigo <a href="#alg%3Aalgoritmo-entrenamiento">2.1</a> que permite, dentro del entrenamiento, crear dos procesos que permitan, por un lado entrenar, y por otro validar que el error obtenido esté dentro de un umbral.</p><p>El proceso anterior se repite hasta encontrar un valor de error aceptable o hasta que se prueben todas las configuraciones posibles para luego elegir la de menor error.</p><p> 
<span style="font-size:small">[1] 
</span><span style="font-size:small"><span style="font-style:italic">x</span></span><span style="font-size:small">, </span><span style="font-size:small"><span style="font-style:italic">k</span></span><span style="font-size:small">, umbralError
</span><span style="font-size:small"><span style="font-style:italic">C</span></span><sub><span style="font-size:small"><span style="font-style:italic">k</span></span></sub><span style="font-size:small">, </span><span style="font-size:small">σ </span><sub><span style="font-size:small"><span style="font-style:italic">k</span></span></sub><span style="font-size:small">, </span><span style="font-size:small"><span style="font-style:italic">W</span></span><sub><span style="font-size:small"><span style="font-style:italic">k</span></span></sub></p><p><span style="font-size:small">Obtener los centros </span><span style="font-size:small"><span style="font-style:italic">C</span></span><sub><span style="font-size:small"><span style="font-style:italic">k</span></span></sub><span style="font-size:small"> y radios </span><span style="font-size:small">σ </span><sub><span style="font-size:small"><span style="font-style:italic">k</span></span></sub><span style="font-size:small"> a partir de los datos de entrada </span><span style="font-size:small"><span style="font-style:italic">x</span></span><span style="font-size:small"> para </span><span style="font-size:small"><span style="font-style:italic">k</span></span><span style="font-size:small"> neuronas.
Obtener la salida de la capa oculta, evaluando con la función de transferencia. 
Por ejemplo, la función Gaussiana:
</span></p><table class="display dcenter"><tr style="vertical-align:middle"><td class="dcell"><span style="font-size:small">φ</span><sub><span style="font-size:small"><span style="font-style:italic">i</span></span></sub><span style="font-size:small"> (</span><span style="font-size:small"><span style="font-style:italic">x</span></span><span style="font-size:small">) = </span><span style="font-size:small">exp</span><span style="font-size:small">(−</span></td><td class="dcell"><table class="display"><tr><td class="dcell" style="text-align:center"><span style="font-size:small">||</span><span style="font-size:small"><span style="font-style:italic">x</span></span><span style="font-size:small">−</span><span style="font-size:small"><span style="font-style:italic">C</span></span><sub><span style="font-size:small"><span style="font-style:italic">i</span></span></sub><span style="font-size:small">||</span></td></tr>
<tr><td class="hbar"><span style="font-size:small"></span></td></tr>
<tr><td class="dcell" style="text-align:center"><span style="font-size:small">2σ</span><sub><span style="font-size:small"><span style="font-style:italic">i</span></span></sub><sup><span style="font-size:small">2</span></sup></td></tr>
</table></td><td class="dcell"><span style="font-size:small">)
</span></td></tr>
</table><p><span style="font-size:small">
Calcular pesos, por ejemplo utilizando matriz pseudoinversa:
</span></p><table class="display dcenter"><tr style="vertical-align:middle"><td class="dcell"><span style="font-size:small"><span style="font-style:italic">W</span></span><sub><span style="font-size:small"><span style="font-style:italic">k</span></span></sub><span style="font-size:small"> = (φ </span><sub><span style="font-size:small"><span style="font-style:italic">k</span></span></sub><sup><span style="font-size:small"><span style="font-style:italic">T</span></span></sup><span style="font-size:small"> φ </span><sub><span style="font-size:small"><span style="font-style:italic">k</span></span></sub><span style="font-size:small">)</span><sup><span style="font-size:small">−1</span></sup><span style="font-size:small"> φ </span><sub><span style="font-size:small"><span style="font-style:italic">k</span></span></sub><sup><span style="font-size:small"><span style="font-style:italic">T</span></span></sup><span style="font-size:small"> </span><span style="font-size:small"><span style="font-style:italic">S</span></span><span style="font-size:small">
</span></td></tr>
</table><p><span style="font-size:small">
(</span><span style="font-size:small"><span style="font-style:italic">S</span></span><span style="font-size:small"> es la salida deseada)</span></p><p><span style="font-size:small">Evaluar la salida de la red: </span><span style="font-size:small"><span style="font-style:italic">Y</span></span><span style="font-size:small"> = φ </span><sub><span style="font-size:small"><span style="font-style:italic">k</span></span></sub><span style="font-size:small"> * </span><span style="font-size:small"><span style="font-style:italic">W</span></span><sub><span style="font-size:small"><span style="font-style:italic">k</span></span></sub><span style="font-size:small">
Calcular el </span><span style="font-size:small"><span style="font-style:italic">error</span></span><span style="font-size:small"> de clasificación.
</span><span style="font-size:small">error</span><span style="font-size:small">&lt;</span><span style="font-size:small">umbralError</span><span style="font-size:small">
	</span><span style="font-size:small"><span style="font-style:italic">C</span></span><sub><span style="font-size:small"><span style="font-style:italic">k</span></span></sub><span style="font-size:small">, </span><span style="font-size:small">σ </span><sub><span style="font-size:small"><span style="font-style:italic">k</span></span></sub><span style="font-size:small">, </span><span style="font-size:small"><span style="font-style:italic">W</span></span><sub><span style="font-size:small"><span style="font-style:italic">k</span></span></sub><span style="font-size:small">
</span><span style="font-size:small">No haya más configuraciones</span><span style="font-size:small">
</span><span style="font-size:small"><span style="font-style:italic">C</span></span><sub><span style="font-size:small"><span style="font-style:italic">k</span></span></sub><span style="font-size:small">, </span><span style="font-size:small">σ </span><sub><span style="font-size:small"><span style="font-style:italic">k</span></span></sub><span style="font-size:small">, </span><span style="font-size:small"><span style="font-style:italic">W</span></span><sub><span style="font-size:small"><span style="font-style:italic">k</span></span></sub><span style="font-size:small">
</span><span style="font-size:small"> 
</span><span style="font-size:small">Metodología de entrenamiento</span><span style="font-size:small"> 
</span><a id="alg:algoritmo-entrenamiento"></a><span style="font-size:small">
</span></p>
<!--TOC subsection id="sec4" Clasificación en una RBFN-->
<h3 id="sec4" class="subsection">2.2  Clasificación en una RBFN</h3><!--SEC END --><p> <a id="sub:clasificaci_n_en_una_rna"></a>
Como se ha mencionado, la clasificación y el entrenamiento tienen como punto común la función de activación.
En el Pseudocódigo <a href="#alg%3Aalgoritmo-clasificacion">2.2</a> se muestra el algoritmo que permitiría realizar la clasificación de datos utilizando los pesos, radios y centroides calculados durante la etapa de entrenamiento.
En este algoritmo, lo único que se realiza es la alimentación de la red neuronal con los parámetros mencionados anteriormente y calcular la salida de la red.
La salida, un número, es entonces evaluada bajo un umbral para decidir la clase que se le asigna al dato</p><p> 
<span style="font-size:small">[1] 
</span><span style="font-size:small"><span style="font-style:italic">X</span></span><span style="font-size:small">, </span><span style="font-size:small"><span style="font-style:italic">Y</span></span><span style="font-size:small">, </span><span style="font-size:small"><span style="font-style:italic">W</span></span><sub><span style="font-size:small"><span style="font-style:italic">ij</span></span></sub><span style="font-size:small">, </span><span style="font-size:small"><span style="font-style:italic">W</span></span><sub><span style="font-size:small"><span style="font-style:italic">jk</span></span></sub><span style="font-size:small">
</span><span style="font-size:small"><span style="font-style:italic">Y</span></span><sub><span style="font-size:small"><span style="font-style:italic">p</span></span></sub><span style="font-size:small">, 
Salida en capa oculta:
</span><span style="font-size:small">φ</span><sub><span style="font-size:small"><span style="font-style:italic">i</span></span></sub><span style="font-size:small"> (</span><span style="font-size:small"><span style="font-style:italic">x</span></span><span style="font-size:small">) = </span><span style="font-size:small">exp</span><span style="font-size:small">(−</span><span style="font-size:small">||</span><span style="font-size:small"><span style="font-style:italic">x</span></span><span style="font-size:small">−</span><span style="font-size:small"><span style="font-style:italic">C</span></span><sub><span style="font-size:small"><span style="font-style:italic">i</span></span></sub><span style="font-size:small">||/2σ</span><sub><span style="font-size:small"><span style="font-style:italic">i</span></span></sub><sup><span style="font-size:small">2</span></sup><span style="font-size:small">)</span></p><p><span style="font-size:small">Salida en capa de salida:
</span><span style="font-size:small"><span style="font-style:italic">Y</span></span><span style="font-size:small"> = φ </span><sub><span style="font-size:small"><span style="font-style:italic">k</span></span></sub><span style="font-size:small"> * </span><span style="font-size:small"><span style="font-style:italic">W</span></span><sub><span style="font-size:small"><span style="font-style:italic">k</span></span></sub><span style="font-size:small">
</span><span style="font-size:small"><span style="font-style:italic">Y</span></span><sub><span style="font-size:small"><span style="font-style:italic">p</span></span><sub><span style="font-size:small"><span style="font-style:italic">i</span></span></sub></sub><span style="font-size:small"> = </span><span style="font-size:small"><span style="font-style:italic">Y</span></span><span style="font-size:small"> &gt; 0.5? 1 : 0,  ∀ </span><span style="font-size:small"><span style="font-style:italic">i</span></span><span style="font-size:small"> = 1,2,⋯,</span><span style="font-size:small"><span style="font-style:italic">N</span></span></p><p><span style="font-size:small"><span style="font-style:italic">Y</span></span><sub><span style="font-size:small"><span style="font-style:italic">p</span></span></sub><span style="font-size:small">
</span><span style="font-size:small"> 
</span><span style="font-size:small">Algoritmo de clasificacion</span><span style="font-size:small"> 
</span><a id="alg:algoritmo-clasificacion"></a><span style="font-size:small">
</span></p>
<!--TOC section id="sec5" Metodología-->
<h2 id="sec5" class="section">3  Metodología</h2><!--SEC END --><p>
<a id="sec:metodologia"></a>
La metodología seguida se sujetó por completo a las etapas de entrenamiento y clasificación mostradas en el marco teórico de la Sección <a href="#sec%3Amarco_teorico">2</a>.</p><p>Se implementaron dos funciones correspondientes al entrenamiento y la clasificación utilizando <em>Matlab</em>.
Con la intención de probar distintas alternativas en la configuración de parámetros se seleccionó el conjunto de parámetros mostrados en la Tabla <a href="#tbl%3Aparametros">1</a>, realizando la ejecución de la combinación de todos ellos a manera de malla.
La prueba de cada configuración de parámetros fue probada 31 veces, debido al componente aleatorio existente al realizar el algoritmo <em>k-means</em>.</p><p>El código para realizar la prueba de las configuraciones fue preparado para comportarse de forma similar al Pseudocódigo <a href="#alg%3Aalgoritmo-entrenamiento">2.1</a>, desempeñando entonces las labores de entrenamiento y validación, con un enfoque híbrido mediante <em>k-means</em> y el método de la matriz pseudoinversa.</p><blockquote class="table"><div class="center"><div class="center"><hr style="width:80%;height:2"></div>
<table style="border-spacing:6px;border-collapse:separate;" class="cellpading0"><tr><td style="text-align:center;white-space:nowrap" ><span style="font-weight:bold">Parámetro</span></td><td style="text-align:center;white-space:nowrap" ><span style="font-weight:bold">Valores</span> </td></tr>
<tr><td style="text-align:center;white-space:nowrap" ><span style="font-style:italic">H</span> (neuronas en capa oculta)</td><td style="text-align:left;white-space:nowrap" >3 a 40 </td></tr>
<tr><td style="text-align:center;white-space:nowrap" >Tipos de media</td><td style="text-align:left;white-space:nowrap" >Uniforme y geométrica</td></tr>
</table>
<div class="caption"><table style="border-spacing:6px;border-collapse:separate;" class="cellpading0"><tr><td style="vertical-align:top;text-align:left;" >Table 1: Configuración de parámetros para la ejecución de las RBFN</td></tr>
</table></div>
<a id="tbl:parametros"></a>
<div class="center"><hr style="width:80%;height:2"></div></div></blockquote>
<!--TOC section id="sec6" Resultados-->
<h2 id="sec6" class="section">4  Resultados</h2><!--SEC END --><p> 
<a id="sec:resultados"></a>
La experimentación fue realizada en un equipo de cómputo con un procesador Intel core i7 de 8 núcleos a 2.00 GHz con 6 GB de memoria en RAM.</p><p>La Tabla <a href="#tab%3Abest-rna">2</a> muestra un resumen de las mejores ejecuciones para cada uno de los datasets.
Es importante hacer notar, que estas mejores configuraciones se refieren a los mejores valores obtenidos en el proceso de entrenamiento.</p><p>La serie de Figuras figs. <a href="#fig%3Aespacio-particionado-complex">1</a>, <a href="#fig%3Aespacio-particionado-linear">2</a>, <a href="#fig%3Aespacio-particionado-ring">3</a> and <a href="#fig%3Aespacio-particionado-xor">4</a> muestra el espacio particionado obtenido por las mejores configuraciones de parámetros con las que se lanzó la ejecución del entrenamiento y clasificación de las RBFN.
Se entiende por <em>mejor</em> configuración a aquella que obtuvo el menor error.
Es importante mencionar también, que los porcentajes de error reportados en la Tabla <a href="#tab%3Abest-rna">2</a> no coinciden exactamente con los mostrados en las figuras ya que éstas últimas utilizan datos distintos.</p><blockquote class="table"><div class="center"><div class="center"><hr style="width:80%;height:2"></div>
<table style="border-spacing:6px;border-collapse:separate;" class="cellpading0"><tr><td style="text-align:center;white-space:nowrap" ><span style="font-weight:bold">Dataset</span></td><td style="text-align:center;white-space:nowrap" ><span style="font-weight:bold">Error mín.</span></td><td style="text-align:center;white-space:nowrap" ><span style="font-weight:bold">H (cantidad neuronas)</span> </td></tr>
<tr><td style="text-align:left;white-space:nowrap" >complex</td><td style="text-align:left;white-space:nowrap" >0.0520</td><td style="text-align:left;white-space:nowrap" >39 </td></tr>
<tr><td style="text-align:left;white-space:nowrap" >linear</td><td style="text-align:left;white-space:nowrap" >0</td><td style="text-align:left;white-space:nowrap" >9 </td></tr>
<tr><td style="text-align:left;white-space:nowrap" >ring</td><td style="text-align:left;white-space:nowrap" >0</td><td style="text-align:left;white-space:nowrap" >10 </td></tr>
<tr><td style="text-align:left;white-space:nowrap" >xor</td><td style="text-align:left;white-space:nowrap" >0</td><td style="text-align:left;white-space:nowrap" >4 </td></tr>
</table>
<div class="caption"><table style="border-spacing:6px;border-collapse:separate;" class="cellpading0"><tr><td style="vertical-align:top;text-align:left;" >Table 2: Mejores RBFN obtenidas</td></tr>
</table></div>
<a id="tab:best-rna"></a>
<div class="center"><hr style="width:80%;height:2"></div></div></blockquote><blockquote class="figure"><div class="center"><div class="center"><hr style="width:80%;height:2"></div>
		<img src="report001.png">
	<div class="caption"><table style="border-spacing:6px;border-collapse:separate;" class="cellpading0"><tr><td style="vertical-align:top;text-align:left;" >Figure 1: Espacio particionado de la mejor RBFN para el dataset <em>complex</em></td></tr>
</table></div>
	<a id="fig:espacio-particionado-complex"></a>
<div class="center"><hr style="width:80%;height:2"></div></div></blockquote><blockquote class="figure"><div class="center"><div class="center"><hr style="width:80%;height:2"></div>
		<img src="report002.png">
	<div class="caption"><table style="border-spacing:6px;border-collapse:separate;" class="cellpading0"><tr><td style="vertical-align:top;text-align:left;" >Figure 2: Espacio particionado de la mejor RBFN para el dataset <em>linear</em></td></tr>
</table></div>
	<a id="fig:espacio-particionado-linear"></a>
<div class="center"><hr style="width:80%;height:2"></div></div></blockquote><blockquote class="figure"><div class="center"><div class="center"><hr style="width:80%;height:2"></div>
		<img src="report003.png">
	<div class="caption"><table style="border-spacing:6px;border-collapse:separate;" class="cellpading0"><tr><td style="vertical-align:top;text-align:left;" >Figure 3: Espacio particionado de la mejor RBFN para el dataset <em>ring</em></td></tr>
</table></div>
	<a id="fig:espacio-particionado-ring"></a>
<div class="center"><hr style="width:80%;height:2"></div></div></blockquote><blockquote class="figure"><div class="center"><div class="center"><hr style="width:80%;height:2"></div>
		<img src="report004.png">
	<div class="caption"><table style="border-spacing:6px;border-collapse:separate;" class="cellpading0"><tr><td style="vertical-align:top;text-align:left;" >Figure 4: Espacio particionado de la mejor RBFN para el dataset <em>xor</em></td></tr>
</table></div>
	<a id="fig:espacio-particionado-xor"></a>
<div class="center"><hr style="width:80%;height:2"></div></div></blockquote>
<!--TOC section id="sec7" Discusión de resultados-->
<h2 id="sec7" class="section">5  Discusión de resultados</h2><!--SEC END --><p>
<a id="sec:discusion"></a>
Las RBFN implementadas obtienen valores de error muy bajos para los datasets <em>linear</em>, <em>ring</em> y <em>xor</em>.
Para el caso del dataset <em>complex</em>, los resultados de error aumentan de forma considerable, tal como en el caso de las RNA MLP implementadas en la asignación anterior.</p><p>Un aspecto importante a destacar es la rapidez con la que la combinación de métodos entregan los resultados.
Fueron implementadas 31 ejecuciones para cada una de las configuraciones de parámetros.
Si bien es cierto que son menos que en la implementación de las RNA MLP de la asignación anterior, es evidente que la rapidez de las RBFN les posicionan como un mejor candidato (de acuerdo a los resultados de los datasets utilizados en esta práctica).</p><p>Adicionalmente, en el aspecto técnico este tipo de redes resultan más fáciles de implementar, considerando las facilidades provistas por <em>Matlab</em>.</p>
<!--TOC section id="sec8" Conclusiones-->
<h2 id="sec8" class="section">6  Conclusiones</h2><!--SEC END --><p>
<a id="sec:conclusiones"></a>
Las RBFN se presentan como una alternativa al perceptrón multicapa para labores de aproximación de funciones y clasificación de patrones.
Este tipo de redes definen una estructra fija de capas de entrada, oculta y de salida, siendo activadas las neuronas por una función no lineal, como por ejemplo la función Gaussiana.</p><p>Debido a su entrenamiento híbrido, algunas de las variantes de entrenamiento de las RBFN no requieren una iteración excesiva ni la retropropagación del error, por lo que su ejecución puede resultar más rápida.</p><p>Este documento ha descrito la implementación y resultados de la ejecución de RBFN con variaciones en la cantidad de neuronas y cálculos de radios, utilizando un entrenamiento híbrido con <em>k-means</em> en la etapa no supervisada y el método de la matriz pseudoinversa en la etapa supervisada sobre cuatro datasets.
Los resultados indican que este tipo de redes pueden desempeñarse de forma más rápida y obtener mejores resultados (para los datasets considerados) en la clasificación que las redes de tipo MLP.</p><!--CUT END -->
<!--HTMLFOOT-->
<!--ENDHTML-->
<!--FOOTER-->
<hr style="height:2"><blockquote class="quote"><em>This document was translated from L<sup>A</sup>T<sub>E</sub>X by
</em><a href="http://hevea.inria.fr/index.html"><em>H</em><em><span style="font-size:small"><sup>E</sup></span></em><em>V</em><em><span style="font-size:small"><sup>E</sup></span></em><em>A</em></a><em>.</em></blockquote></body>
</html>
